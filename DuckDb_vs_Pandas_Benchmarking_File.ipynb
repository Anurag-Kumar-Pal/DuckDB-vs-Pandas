{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e537177b",
   "metadata": {},
   "source": [
    "# Benchmark Comparison: DuckDB vs Pandas \n",
    "\n",
    "**Author:** Anurag Kumar Pal\n",
    "<br>\n",
    "**Email:** iampalanurag@gmail.com  \n",
    "**GitHub:** [Anurag-Kumar-Pal](https://github.com/Anurag-Kumar-Pal)  \n",
    "**Date:** 2026-02-10  \n",
    "**Description:** Benchmarkig Runtime for DuckDB and Pandas.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Importing the Libraries](#Importing-the-Libraries)\n",
    "2. [Data Wrangling using the Pandas Library](#Data-Wrangling-using-the-Pandas-Library)\n",
    "3. [Data Wrangling using the DuckDB Library](#Data-Wrangling-using-the-DuckDB-Library)\n",
    "4. [Results](#Results)\n",
    "5. [Conclusions](#Conclusions)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138d6ace",
   "metadata": {},
   "source": [
    "### Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "640aa896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import duckdb as db\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d50b8",
   "metadata": {},
   "source": [
    "### Data Wrangling using the Pandas Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2a2439",
   "metadata": {},
   "source": [
    "##### A. Loading the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "513775db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 281 ms\n",
      "Wall time: 279 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Datase File for 50k records\n",
    "\n",
    "pdf_50k_rows = pd.read_csv(r\"C:\\Users\\heyit\\Desktop\\Jupyter Notebooks\\PB Notebooks\\AKP_Tech_Playground\\DuckDB vs Pandas\\Input_Files\\50K_Rows.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5b85a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 719 ms\n",
      "Wall time: 767 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Datase File for 100k records\n",
    "\n",
    "pdf_100k_rows = pd.read_csv(r\"C:\\Users\\heyit\\Desktop\\Jupyter Notebooks\\PB Notebooks\\AKP_Tech_Playground\\DuckDB vs Pandas\\Input_Files\\100K_Rows.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e282a9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.95 s\n",
      "Wall time: 6.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Datase File for 500k records\n",
    "\n",
    "pdf_500k_rows = pd.read_csv(r\"C:\\Users\\heyit\\Desktop\\Jupyter Notebooks\\PB Notebooks\\AKP_Tech_Playground\\DuckDB vs Pandas\\Input_Files\\500K_Rows.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69f0f3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8.31 s\n",
      "Wall time: 8.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Datase File for 1.5M records\n",
    "\n",
    "pdf_1point5m_rows = pd.read_csv(r\"C:\\Users\\heyit\\Desktop\\Jupyter Notebooks\\PB Notebooks\\AKP_Tech_Playground\\DuckDB vs Pandas\\Input_Files\\1.5M_Rows.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc26c7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 35s\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Datase File for 4M records\n",
    "\n",
    "pdf_4m_rows = pd.read_csv(r\"C:\\Users\\heyit\\Desktop\\Jupyter Notebooks\\PB Notebooks\\AKP_Tech_Playground\\DuckDB vs Pandas\\Input_Files\\4M_Rows.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d719ffb5",
   "metadata": {},
   "source": [
    "##### B. Checking the # of Rows and Columns for each Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4269b129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(48895, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Record Count for 50k records\n",
    "\n",
    "pdf_50k_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81be7651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(114000, 21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Record Count for 100k records\n",
    "\n",
    "pdf_100k_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2fa77dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(568454, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Record Count for 500k records\n",
    "\n",
    "pdf_500k_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26d5e96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1444963, 11)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Record Count for 1.5M records\n",
    "\n",
    "pdf_1point5m_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92768a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3906160, 21)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Record Count for 4M records\n",
    "\n",
    "pdf_4m_rows.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f631e76a",
   "metadata": {},
   "source": [
    "##### C.  Checking the \"Sort\" Command on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e247a2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 36.1 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14119</th>\n",
       "      <td>10830083</td>\n",
       "      <td>Beautiful well kept private home!</td>\n",
       "      <td>56078939</td>\n",
       "      <td>Tony</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Tottenville</td>\n",
       "      <td>40.49979</td>\n",
       "      <td>-74.24084</td>\n",
       "      <td>Private room</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46919</th>\n",
       "      <td>35489384</td>\n",
       "      <td>Cozy Apartment</td>\n",
       "      <td>236186921</td>\n",
       "      <td>Iveth</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Tottenville</td>\n",
       "      <td>40.50641</td>\n",
       "      <td>-74.23059</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-06-28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15278</th>\n",
       "      <td>12230928</td>\n",
       "      <td>Villa DiGioia visit NYC via SI</td>\n",
       "      <td>65806798</td>\n",
       "      <td>Michael J</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Tottenville</td>\n",
       "      <td>40.50708</td>\n",
       "      <td>-74.24285</td>\n",
       "      <td>Private room</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>639199</td>\n",
       "      <td>Beautiful 4BR/4BA Home, Staten Island, NY City.</td>\n",
       "      <td>1483081</td>\n",
       "      <td>Marina</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Tottenville</td>\n",
       "      <td>40.50868</td>\n",
       "      <td>-74.23986</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>299</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>2019-07-08</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23460</th>\n",
       "      <td>18997371</td>\n",
       "      <td>Cozy Getaway</td>\n",
       "      <td>90104417</td>\n",
       "      <td>Sueann</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Tottenville</td>\n",
       "      <td>40.50873</td>\n",
       "      <td>-74.23914</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>2.08</td>\n",
       "      <td>2</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                             name    host_id  \\\n",
       "14119  10830083                Beautiful well kept private home!   56078939   \n",
       "46919  35489384                                   Cozy Apartment  236186921   \n",
       "15278  12230928                   Villa DiGioia visit NYC via SI   65806798   \n",
       "1424     639199  Beautiful 4BR/4BA Home, Staten Island, NY City.    1483081   \n",
       "23460  18997371                                     Cozy Getaway   90104417   \n",
       "\n",
       "       host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
       "14119       Tony       Staten Island   Tottenville  40.49979  -74.24084   \n",
       "46919      Iveth       Staten Island   Tottenville  40.50641  -74.23059   \n",
       "15278  Michael J       Staten Island   Tottenville  40.50708  -74.24285   \n",
       "1424      Marina       Staten Island   Tottenville  40.50868  -74.23986   \n",
       "23460     Sueann       Staten Island   Tottenville  40.50873  -74.23914   \n",
       "\n",
       "             room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "14119     Private room    110               2                  0         NaN   \n",
       "46919  Entire home/apt     75               1                  1  2019-06-28   \n",
       "15278     Private room    100               2                  0         NaN   \n",
       "1424   Entire home/apt    299               3                 59  2019-07-08   \n",
       "23460  Entire home/apt     85               2                 49  2019-07-01   \n",
       "\n",
       "       reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "14119                NaN                               1               364  \n",
       "46919               1.00                               1               299  \n",
       "15278                NaN                               1               365  \n",
       "1424                0.82                               1               245  \n",
       "23460               2.08                               2               159  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Sorting Data for 50k records\n",
    "\n",
    "pdf_50k_rows.sort_values(\"latitude\").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2484a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 62.5 ms\n",
      "Wall time: 51.4 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65900</th>\n",
       "      <td>65900</td>\n",
       "      <td>1kR4gIb7nGxHPI3D2ifs59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.5830</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.460</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0605</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.00396</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.734</td>\n",
       "      <td>138.391</td>\n",
       "      <td>4</td>\n",
       "      <td>k-pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59310</th>\n",
       "      <td>59310</td>\n",
       "      <td>6hsyfegVY5yklJneM40mWi</td>\n",
       "      <td>Leila Bela</td>\n",
       "      <td>Angra Manyu</td>\n",
       "      <td>The Exorsism Begins...</td>\n",
       "      <td>0</td>\n",
       "      <td>8586</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>...</td>\n",
       "      <td>-29.714</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.95600</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>iranian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59812</th>\n",
       "      <td>59812</td>\n",
       "      <td>38Ogh3rsHba83kXx13gbKs</td>\n",
       "      <td>Leila Bela</td>\n",
       "      <td>Angra Manyu</td>\n",
       "      <td>V-4</td>\n",
       "      <td>0</td>\n",
       "      <td>13386</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.196</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.9070</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>iranian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59775</th>\n",
       "      <td>59775</td>\n",
       "      <td>1HVjSh7scH1PaPiLjy2LEu</td>\n",
       "      <td>Leila Bela;Leila's Opera Class</td>\n",
       "      <td>Angra Manyu</td>\n",
       "      <td>Screams for a Finale! (feat. Leila's Opera Class)</td>\n",
       "      <td>0</td>\n",
       "      <td>15800</td>\n",
       "      <td>False</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.5080</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.564</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3160</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.99900</td>\n",
       "      <td>0.9520</td>\n",
       "      <td>0.000</td>\n",
       "      <td>184.051</td>\n",
       "      <td>3</td>\n",
       "      <td>iranian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16856</th>\n",
       "      <td>16856</td>\n",
       "      <td>5YKCM3jbJ8lqUXUwfU7KwZ</td>\n",
       "      <td>Wolfgang Amadeus Mozart;Ingrid Haebler</td>\n",
       "      <td>Mozart: The Complete Piano Sonatas</td>\n",
       "      <td>Andante in C Major, K. 1a</td>\n",
       "      <td>0</td>\n",
       "      <td>17453</td>\n",
       "      <td>False</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.0301</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.518</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>0.000</td>\n",
       "      <td>84.375</td>\n",
       "      <td>4</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                track_id  \\\n",
       "65900       65900  1kR4gIb7nGxHPI3D2ifs59   \n",
       "59310       59310  6hsyfegVY5yklJneM40mWi   \n",
       "59812       59812  38Ogh3rsHba83kXx13gbKs   \n",
       "59775       59775  1HVjSh7scH1PaPiLjy2LEu   \n",
       "16856       16856  5YKCM3jbJ8lqUXUwfU7KwZ   \n",
       "\n",
       "                                      artists  \\\n",
       "65900                                     NaN   \n",
       "59310                              Leila Bela   \n",
       "59812                              Leila Bela   \n",
       "59775          Leila Bela;Leila's Opera Class   \n",
       "16856  Wolfgang Amadeus Mozart;Ingrid Haebler   \n",
       "\n",
       "                               album_name  \\\n",
       "65900                                 NaN   \n",
       "59310                         Angra Manyu   \n",
       "59812                         Angra Manyu   \n",
       "59775                         Angra Manyu   \n",
       "16856  Mozart: The Complete Piano Sonatas   \n",
       "\n",
       "                                              track_name  popularity  \\\n",
       "65900                                                NaN           0   \n",
       "59310                             The Exorsism Begins...           0   \n",
       "59812                                                V-4           0   \n",
       "59775  Screams for a Finale! (feat. Leila's Opera Class)           0   \n",
       "16856                          Andante in C Major, K. 1a           0   \n",
       "\n",
       "       duration_ms  explicit  danceability  energy  ...  loudness  mode  \\\n",
       "65900            0     False         0.501  0.5830  ...    -9.460     0   \n",
       "59310         8586     False         0.000  0.0400  ...   -29.714     0   \n",
       "59812        13386     False         0.000  0.2240  ...   -22.196     1   \n",
       "59775        15800     False         0.251  0.5080  ...   -10.564     0   \n",
       "16856        17453     False         0.467  0.0301  ...   -28.518     0   \n",
       "\n",
       "       speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "65900       0.0605         0.690           0.00396    0.0747    0.734   \n",
       "59310       0.0000         0.928           0.95600    0.1150    0.000   \n",
       "59812       0.0000         0.970           0.00000    0.9070    0.000   \n",
       "59775       0.3160         0.969           0.99900    0.9520    0.000   \n",
       "16856       0.0428         0.995           0.90000    0.1240    0.000   \n",
       "\n",
       "         tempo  time_signature  track_genre  \n",
       "65900  138.391               4        k-pop  \n",
       "59310    0.000               0      iranian  \n",
       "59812    0.000               0      iranian  \n",
       "59775  184.051               3      iranian  \n",
       "16856   84.375               4    classical  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Sorting Data for 100k records\n",
    "\n",
    "pdf_100k_rows.sort_values(\"duration_ms\").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff747928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 250 ms\n",
      "Wall time: 249 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150523</th>\n",
       "      <td>150524</td>\n",
       "      <td>6641040</td>\n",
       "      <td>ACITT7DI6IDDL</td>\n",
       "      <td>shari zychinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>939340800</td>\n",
       "      <td>EVERY book is educational</td>\n",
       "      <td>this witty little book makes my son laugh at l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150500</th>\n",
       "      <td>150501</td>\n",
       "      <td>6641040</td>\n",
       "      <td>AJ46FKXOVC7NR</td>\n",
       "      <td>Nicholas A Mesiano</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>940809600</td>\n",
       "      <td>This whole series is great way to spend time w...</td>\n",
       "      <td>I can remember seeing the show when it aired o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451855</th>\n",
       "      <td>451856</td>\n",
       "      <td>B00004CXX9</td>\n",
       "      <td>AIUWLEQ1ADEG5</td>\n",
       "      <td>Elizabeth Medina</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>944092800</td>\n",
       "      <td>Entertainingl Funny!</td>\n",
       "      <td>Beetlejuice is a well written movie ..... ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230284</th>\n",
       "      <td>230285</td>\n",
       "      <td>B00004RYGX</td>\n",
       "      <td>A344SMIA5JECGM</td>\n",
       "      <td>Vincent P. Ross</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>944438400</td>\n",
       "      <td>A modern day fairy tale</td>\n",
       "      <td>A twist of rumplestiskin captured on film, sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451877</th>\n",
       "      <td>451878</td>\n",
       "      <td>B00004CXX9</td>\n",
       "      <td>A344SMIA5JECGM</td>\n",
       "      <td>Vincent P. Ross</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>944438400</td>\n",
       "      <td>A modern day fairy tale</td>\n",
       "      <td>A twist of rumplestiskin captured on film, sta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId         ProfileName  \\\n",
       "150523  150524     6641040   ACITT7DI6IDDL     shari zychinski   \n",
       "150500  150501     6641040   AJ46FKXOVC7NR  Nicholas A Mesiano   \n",
       "451855  451856  B00004CXX9   AIUWLEQ1ADEG5    Elizabeth Medina   \n",
       "230284  230285  B00004RYGX  A344SMIA5JECGM     Vincent P. Ross   \n",
       "451877  451878  B00004CXX9  A344SMIA5JECGM     Vincent P. Ross   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score       Time  \\\n",
       "150523                     0                       0      5  939340800   \n",
       "150500                     2                       2      5  940809600   \n",
       "451855                     0                       0      5  944092800   \n",
       "230284                     1                       2      5  944438400   \n",
       "451877                     1                       2      5  944438400   \n",
       "\n",
       "                                                  Summary  \\\n",
       "150523                          EVERY book is educational   \n",
       "150500  This whole series is great way to spend time w...   \n",
       "451855                               Entertainingl Funny!   \n",
       "230284                            A modern day fairy tale   \n",
       "451877                            A modern day fairy tale   \n",
       "\n",
       "                                                     Text  \n",
       "150523  this witty little book makes my son laugh at l...  \n",
       "150500  I can remember seeing the show when it aired o...  \n",
       "451855  Beetlejuice is a well written movie ..... ever...  \n",
       "230284  A twist of rumplestiskin captured on film, sta...  \n",
       "451877  A twist of rumplestiskin captured on film, sta...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Sorting Data for 500k records\n",
    "\n",
    "pdf_500k_rows.sort_values(\"Time\").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30d16db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.89 s\n",
      "Wall time: 2.17 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>reviewId</th>\n",
       "      <th>creationDate</th>\n",
       "      <th>criticName</th>\n",
       "      <th>isTopCritic</th>\n",
       "      <th>originalScore</th>\n",
       "      <th>reviewState</th>\n",
       "      <th>publicatioName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>scoreSentiment</th>\n",
       "      <th>reviewUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155743</th>\n",
       "      <td>ballad_of_aj_weberman</td>\n",
       "      <td>1914317</td>\n",
       "      <td>1800-01-01</td>\n",
       "      <td>Jennie Kermode</td>\n",
       "      <td>False</td>\n",
       "      <td>5/5</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Eye for Film</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>http://www.eyeforfilm.co.uk/reviews.php?id=8266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168836</th>\n",
       "      <td>lucky_country</td>\n",
       "      <td>1904549</td>\n",
       "      <td>1800-01-01</td>\n",
       "      <td>Thomas Caldwell</td>\n",
       "      <td>False</td>\n",
       "      <td>2/5</td>\n",
       "      <td>rotten</td>\n",
       "      <td>Cinema Autopsy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>http://blog.cinemaautopsy.com/2009/07/14/film-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278238</th>\n",
       "      <td>the_definition_of_insanity</td>\n",
       "      <td>1905309</td>\n",
       "      <td>1800-01-01</td>\n",
       "      <td>Joe Lozito</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5/4</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Big Picture Big Sound</td>\n",
       "      <td>I don't know how autobiographical this film is...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>http://www.bigpicturebigsound.com/The-Definiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947162</th>\n",
       "      <td>juice</td>\n",
       "      <td>1897051</td>\n",
       "      <td>1800-01-01</td>\n",
       "      <td>Owen Gleiberman</td>\n",
       "      <td>True</td>\n",
       "      <td>B+</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Entertainment Weekly</td>\n",
       "      <td>Coming out from behind Spike Lee's camera, Ern...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>http://www.ew.com/ew/article/0,,309271,00.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060329</th>\n",
       "      <td>heartless-2009</td>\n",
       "      <td>1917013</td>\n",
       "      <td>1800-01-01</td>\n",
       "      <td>Tim Robey</td>\n",
       "      <td>True</td>\n",
       "      <td>3/5</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Daily Telegraph (UK)</td>\n",
       "      <td>It's exciting to see a British horror film wit...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>http://www.telegraph.co.uk/culture/film/filmre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  reviewId creationDate       criticName  \\\n",
       "155743        ballad_of_aj_weberman   1914317   1800-01-01   Jennie Kermode   \n",
       "168836                lucky_country   1904549   1800-01-01  Thomas Caldwell   \n",
       "278238   the_definition_of_insanity   1905309   1800-01-01       Joe Lozito   \n",
       "947162                        juice   1897051   1800-01-01  Owen Gleiberman   \n",
       "1060329              heartless-2009   1917013   1800-01-01        Tim Robey   \n",
       "\n",
       "         isTopCritic originalScore reviewState         publicatioName  \\\n",
       "155743         False           5/5       fresh           Eye for Film   \n",
       "168836         False           2/5      rotten         Cinema Autopsy   \n",
       "278238         False         3.5/4       fresh  Big Picture Big Sound   \n",
       "947162          True            B+       fresh   Entertainment Weekly   \n",
       "1060329         True           3/5       fresh   Daily Telegraph (UK)   \n",
       "\n",
       "                                                reviewText scoreSentiment  \\\n",
       "155743                                                 NaN       POSITIVE   \n",
       "168836                                                 NaN       NEGATIVE   \n",
       "278238   I don't know how autobiographical this film is...       POSITIVE   \n",
       "947162   Coming out from behind Spike Lee's camera, Ern...       POSITIVE   \n",
       "1060329  It's exciting to see a British horror film wit...       POSITIVE   \n",
       "\n",
       "                                                 reviewUrl  \n",
       "155743     http://www.eyeforfilm.co.uk/reviews.php?id=8266  \n",
       "168836   http://blog.cinemaautopsy.com/2009/07/14/film-...  \n",
       "278238   http://www.bigpicturebigsound.com/The-Definiti...  \n",
       "947162      http://www.ew.com/ew/article/0,,309271,00.html  \n",
       "1060329  http://www.telegraph.co.uk/culture/film/filmre...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Sorting Data for 1.5M records\n",
    "\n",
    "pdf_1point5m_rows.sort_values(\"creationDate\").head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c21a886b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7.95 s\n",
      "Wall time: 8.23 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>universal_name</th>\n",
       "      <th>description</th>\n",
       "      <th>linkedin_url</th>\n",
       "      <th>website_url</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>associated_members_count</th>\n",
       "      <th>verification</th>\n",
       "      <th>founded_on</th>\n",
       "      <th>...</th>\n",
       "      <th>location_branches</th>\n",
       "      <th>logo_url</th>\n",
       "      <th>specialities</th>\n",
       "      <th>industry</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>funding_info</th>\n",
       "      <th>__created_at</th>\n",
       "      <th>__updated_at</th>\n",
       "      <th>claimable</th>\n",
       "      <th>company_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>445842</th>\n",
       "      <td>4057402</td>\n",
       "      <td>Mccormack Photos</td>\n",
       "      <td>mccormack-photos</td>\n",
       "      <td>Denver band photography and album design.</td>\n",
       "      <td>https://www.linkedin.com/company/mccormack-pho...</td>\n",
       "      <td>http://www.mccormickphotos.net/</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"verified\": false}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[{\"name\": \"Jersey City\", \"address\": {\"city\": \"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Photography</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-22 06:24:31.712114+00</td>\n",
       "      <td>2025-06-22 06:24:31.712114+00</td>\n",
       "      <td>t</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451480</th>\n",
       "      <td>4060992</td>\n",
       "      <td>Gourd Music</td>\n",
       "      <td>gourd-music</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/company/gourd-music/</td>\n",
       "      <td>http://www.gourd.com/</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"verified\": false}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[{\"name\": \"Felton\", \"address\": {\"city\": \"Felto...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Music</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-22 06:33:21.873146+00</td>\n",
       "      <td>2025-06-22 06:33:21.873146+00</td>\n",
       "      <td>t</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230725</th>\n",
       "      <td>4584688</td>\n",
       "      <td>Strayhorn Photography</td>\n",
       "      <td>strayhorn-photography</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/company/strayhorn-pho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"verified\": false}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[{\"name\": \"Humboldt\", \"address\": {\"city\": \"Hum...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Photography</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-23 06:11:40.249238+00</td>\n",
       "      <td>2025-06-23 06:11:40.249238+00</td>\n",
       "      <td>t</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723093</th>\n",
       "      <td>3778148</td>\n",
       "      <td>Soluciones de Iluminación</td>\n",
       "      <td>soluciones-de-iluminación</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.linkedin.com/showcase/soluciones-d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{\"verified\": false}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-24 05:28:34.774188+00</td>\n",
       "      <td>2025-06-24 05:28:34.774188+00</td>\n",
       "      <td>f</td>\n",
       "      <td>showcase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230721</th>\n",
       "      <td>4584680</td>\n",
       "      <td>Little Company Inc The</td>\n",
       "      <td>little-company-inc-the</td>\n",
       "      <td>We bring together problem solvers, strategic t...</td>\n",
       "      <td>https://www.linkedin.com/company/little-compan...</td>\n",
       "      <td>http://www.littleco.com/</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{\"verified\": false}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>[{\"name\": \"Prior Lake\", \"address\": {\"city\": \"P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Advertising Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-06-23 06:11:40.249238+00</td>\n",
       "      <td>2025-06-23 06:11:40.249238+00</td>\n",
       "      <td>t</td>\n",
       "      <td>company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                       name             universal_name  \\\n",
       "445842   4057402           Mccormack Photos           mccormack-photos   \n",
       "451480   4060992                Gourd Music                gourd-music   \n",
       "1230725  4584688      Strayhorn Photography      strayhorn-photography   \n",
       "1723093  3778148  Soluciones de Iluminación  soluciones-de-iluminación   \n",
       "1230721  4584680     Little Company Inc The     little-company-inc-the   \n",
       "\n",
       "                                               description  \\\n",
       "445842           Denver band photography and album design.   \n",
       "451480                                                 NaN   \n",
       "1230725                                                NaN   \n",
       "1723093                                                NaN   \n",
       "1230721  We bring together problem solvers, strategic t...   \n",
       "\n",
       "                                              linkedin_url  \\\n",
       "445842   https://www.linkedin.com/company/mccormack-pho...   \n",
       "451480       https://www.linkedin.com/company/gourd-music/   \n",
       "1230725  https://www.linkedin.com/company/strayhorn-pho...   \n",
       "1723093  https://www.linkedin.com/showcase/soluciones-d...   \n",
       "1230721  https://www.linkedin.com/company/little-compan...   \n",
       "\n",
       "                             website_url  followers_count  \\\n",
       "445842   http://www.mccormickphotos.net/              0.0   \n",
       "451480             http://www.gourd.com/              0.0   \n",
       "1230725                              NaN              0.0   \n",
       "1723093                              NaN              0.0   \n",
       "1230721         http://www.littleco.com/              0.0   \n",
       "\n",
       "         associated_members_count         verification founded_on  ...  \\\n",
       "445842                        1.0  {\"verified\": false}        NaN  ...   \n",
       "451480                        1.0  {\"verified\": false}        NaN  ...   \n",
       "1230725                       1.0  {\"verified\": false}        NaN  ...   \n",
       "1723093                       NaN  {\"verified\": false}        NaN  ...   \n",
       "1230721                       0.0  {\"verified\": false}        NaN  ...   \n",
       "\n",
       "                                         location_branches logo_url  \\\n",
       "445842   [{\"name\": \"Jersey City\", \"address\": {\"city\": \"...      NaN   \n",
       "451480   [{\"name\": \"Felton\", \"address\": {\"city\": \"Felto...      NaN   \n",
       "1230725  [{\"name\": \"Humboldt\", \"address\": {\"city\": \"Hum...      NaN   \n",
       "1723093                                                 []      NaN   \n",
       "1230721  [{\"name\": \"Prior Lake\", \"address\": {\"city\": \"P...      NaN   \n",
       "\n",
       "        specialities              industry hashtags funding_info  \\\n",
       "445842           NaN           Photography      NaN          NaN   \n",
       "451480           NaN                 Music      NaN          NaN   \n",
       "1230725          NaN           Photography      NaN          NaN   \n",
       "1723093          NaN                   NaN      NaN          NaN   \n",
       "1230721          NaN  Advertising Services      NaN          NaN   \n",
       "\n",
       "                          __created_at                   __updated_at  \\\n",
       "445842   2025-06-22 06:24:31.712114+00  2025-06-22 06:24:31.712114+00   \n",
       "451480   2025-06-22 06:33:21.873146+00  2025-06-22 06:33:21.873146+00   \n",
       "1230725  2025-06-23 06:11:40.249238+00  2025-06-23 06:11:40.249238+00   \n",
       "1723093  2025-06-24 05:28:34.774188+00  2025-06-24 05:28:34.774188+00   \n",
       "1230721  2025-06-23 06:11:40.249238+00  2025-06-23 06:11:40.249238+00   \n",
       "\n",
       "        claimable company_type  \n",
       "445842          t      company  \n",
       "451480          t      company  \n",
       "1230725         t      company  \n",
       "1723093         f     showcase  \n",
       "1230721         t      company  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Sorting Data for 4M records\n",
    "\n",
    "pdf_4m_rows.sort_values(\"followers_count\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5547c505",
   "metadata": {},
   "source": [
    "##### D.  Checking the \"Aggregation\" Command on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32ce1ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 12.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "room_type\n",
       "Entire home/apt    211.794246\n",
       "Private room        89.780973\n",
       "Shared room         70.127586\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Aggregating Data for 50k records\n",
    "\n",
    "pdf_50k_rows.groupby(\"room_type\")[\"price\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef4e13ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 12.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "track_genre\n",
       "acoustic       214896.957\n",
       "afrobeat       248412.791\n",
       "alt-rock       235455.907\n",
       "alternative    222016.180\n",
       "ambient        237059.038\n",
       "                  ...    \n",
       "techno         312311.477\n",
       "trance         269007.478\n",
       "trip-hop       274954.026\n",
       "turkish        219529.010\n",
       "world-music    297195.622\n",
       "Name: duration_ms, Length: 114, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Aggregating Data for 100k records\n",
    "\n",
    "pdf_100k_rows.groupby(\"track_genre\")[\"duration_ms\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9be795d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 32.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Score\n",
       "1    1.303159e+09\n",
       "2    1.301131e+09\n",
       "3    1.300126e+09\n",
       "4    1.296722e+09\n",
       "5    1.294306e+09\n",
       "Name: Time, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Aggregating Data for 500k records\n",
    "\n",
    "pdf_500k_rows.groupby(\"Score\")[\"Time\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46721b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 188 ms\n",
      "Wall time: 200 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "reviewState\n",
       "fresh     2023-04-08\n",
       "rotten    2023-04-08\n",
       "Name: creationDate, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Aggregating Data for 1.5M records\n",
    "\n",
    "pdf_1point5m_rows.groupby(\"reviewState\")[\"creationDate\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d85fa627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 422 ms\n",
      "Wall time: 433 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "industry\n",
       "Abrasives and Nonmetallic Minerals Manufacturing    62.250000\n",
       "Accessible Architecture and Design                   7.714286\n",
       "Accommodation and Food Services                     54.800000\n",
       "Accounting                                          29.705513\n",
       "Administration of Justice                           18.807198\n",
       "                                                      ...    \n",
       "Wireless Services                                    8.346405\n",
       "Wood Product Manufacturing                          47.346154\n",
       "Writing & Editing                                    8.826317\n",
       "Writing and Editing                                  3.637877\n",
       "Zoos and Botanical Gardens                          60.875000\n",
       "Name: associated_members_count, Length: 523, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Aggregating Data for 4M records\n",
    "\n",
    "pdf_4m_rows.groupby(\"industry\")[\"associated_members_count\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d3f12a",
   "metadata": {},
   "source": [
    "##### E.  Checking the \"Row-Wise Transformation\" Command on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4660db3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 16.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Row-wise Transformation for 50k records\n",
    "\n",
    "pdf_50k_rows[\"price_converted\"] = pdf_50k_rows[\"price\"].apply(lambda x: x * 1.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ed27845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 39.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Row-wise Transformation for 100k records\n",
    "\n",
    "pdf_100k_rows[\"duration_ms_converted\"] = pdf_100k_rows[\"duration_ms\"].apply(lambda x: x * 1.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba8af3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 141 ms\n",
      "Wall time: 136 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Row-wise Transformation for 500k records\n",
    "\n",
    "pdf_500k_rows[\"Time_converted\"] = pdf_500k_rows[\"Time\"].apply(lambda x: x * 1.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80ec1a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 312 ms\n",
      "Wall time: 328 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Row-wise Transformation for 1.5M records\n",
    "\n",
    "pdf_1point5m_rows[\"reviewId_converted\"] = pdf_1point5m_rows[\"reviewId\"].apply(lambda x: x * 1.18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd170c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 750 ms\n",
      "Wall time: 760 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Row-wise Transformation for 4M records\n",
    "\n",
    "pdf_4m_rows[\"associated_members_count_converted\"] = pdf_4m_rows[\"associated_members_count\"].apply(lambda x: x * 1.18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8571c12f",
   "metadata": {},
   "source": [
    "### Data Wrangling using the DuckDB Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f61f7d",
   "metadata": {},
   "source": [
    "##### A. Loading the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "321d91d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record Count:  48895\n",
      "Timings for 50K Rows -->>>\n",
      "DuckDb Lazy Read Time:  0.15 s\n",
      "DuckDB Action Time:  0.21 s\n"
     ]
    }
   ],
   "source": [
    "# DuckDB command to read a dataset for 50k records and convert to Pandas Dataframe\n",
    "# Lazy Read Simulation: Preparing the query\n",
    "start_lazy = time.perf_counter()\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT * FROM read_csv_auto(\n",
    "            'C:\\\\Users\\\\heyit\\\\Desktop\\\\Jupyter Notebooks\\\\PB Notebooks\\\\AKP_Tech_Playground\\\\DuckDB vs Pandas\\\\Input_Files\\\\50K_Rows.csv')\n",
    "        \"\"\"\n",
    "\n",
    "# This prepares the query but doesn't execute it\n",
    "dbf_50k_rows = db.sql(query)\n",
    "lazytime_duckdb = time.perf_counter() - start_lazy\n",
    "\n",
    "# Actual Materialization of the Query\n",
    "start_action = time.perf_counter()\n",
    "\n",
    "# Triggering the DuckDB Query\n",
    "db_count_records = len(dbf_50k_rows.to_df())\n",
    "action_time_duckdb = time.perf_counter() - start_action\n",
    "\n",
    "print(\"Record Count: \", db_count_records)\n",
    "print(\"Timings for 50K Rows -->>>\")\n",
    "print(f\"DuckDb Lazy Read Time: {lazytime_duckdb: .2f} s\")\n",
    "print(f\"DuckDB Action Time: {action_time_duckdb: .2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbf5decf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record Count:  114000\n",
      "Timings for 100K Rows -->>>\n",
      "DuckDb Lazy Read Time:  0.10 s\n",
      "DuckDB Action Time:  0.28 s\n"
     ]
    }
   ],
   "source": [
    "# DuckDB command to read a dataset for 100k records and convert to Pandas Dataframe\n",
    "# Lazy Read Simulation: Preparing the query\n",
    "start_lazy = time.perf_counter()\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT * FROM read_csv_auto(\n",
    "            'C:\\\\Users\\\\heyit\\\\Desktop\\\\Jupyter Notebooks\\\\PB Notebooks\\\\AKP_Tech_Playground\\\\DuckDB vs Pandas\\\\Input_Files\\\\100K_Rows.csv')\n",
    "        \"\"\"\n",
    "\n",
    "# This prepares the query but doesn't execute it\n",
    "dbf_100k_rows = db.sql(query)\n",
    "lazytime_duckdb = time.perf_counter() - start_lazy\n",
    "\n",
    "# Actual Materialization of the Query\n",
    "start_action = time.perf_counter()\n",
    "\n",
    "# Triggering the DuckDB Query\n",
    "db_count_records = len(dbf_100k_rows.to_df())\n",
    "action_time_duckdb = time.perf_counter() - start_action\n",
    "\n",
    "print(\"Record Count: \", db_count_records)\n",
    "print(\"Timings for 100K Rows -->>>\")\n",
    "print(f\"DuckDb Lazy Read Time: {lazytime_duckdb: .2f} s\")\n",
    "print(f\"DuckDB Action Time: {action_time_duckdb: .2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e05f81da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record Count:  568454\n",
      "Timings for 500K Rows -->>>\n",
      "DuckDb Lazy Read Time:  0.11 s\n",
      "DuckDB Action Time:  1.22 s\n"
     ]
    }
   ],
   "source": [
    "# DuckDB command to read a dataset for 500k records and convert to Pandas Dataframe\n",
    "# Lazy Read Simulation: Preparing the query\n",
    "start_lazy = time.perf_counter()\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT * FROM read_csv_auto(\n",
    "            'C:\\\\Users\\\\heyit\\\\Desktop\\\\Jupyter Notebooks\\\\PB Notebooks\\\\AKP_Tech_Playground\\\\DuckDB vs Pandas\\\\Input_Files\\\\500K_Rows.csv')\n",
    "        \"\"\"\n",
    "\n",
    "# This prepares the query but doesn't execute it\n",
    "dbf_500k_rows = db.sql(query)\n",
    "lazytime_duckdb = time.perf_counter() - start_lazy\n",
    "\n",
    "# Actual Materialization of the Query\n",
    "start_action = time.perf_counter()\n",
    "\n",
    "# Triggering the DuckDB Query\n",
    "db_count_records = len(dbf_500k_rows.to_df())\n",
    "action_time_duckdb = time.perf_counter() - start_action\n",
    "\n",
    "print(\"Record Count: \", db_count_records)\n",
    "print(\"Timings for 500K Rows -->>>\")\n",
    "print(f\"DuckDb Lazy Read Time: {lazytime_duckdb: .2f} s\")\n",
    "print(f\"DuckDB Action Time: {action_time_duckdb: .2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b651181e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record Count:  1444963\n",
      "Timings for 1.5M Rows -->>>\n",
      "DuckDb Lazy Read Time:  0.11 s\n",
      "DuckDB Action Time:  3.03 s\n"
     ]
    }
   ],
   "source": [
    "# DuckDB command to read a dataset for 1.5M records and convert to Pandas Dataframe\n",
    "# Lazy Read Simulation: Preparing the query\n",
    "start_lazy = time.perf_counter()\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT * FROM read_csv_auto(\n",
    "            'C:\\\\Users\\\\heyit\\\\Desktop\\\\Jupyter Notebooks\\\\PB Notebooks\\\\AKP_Tech_Playground\\\\DuckDB vs Pandas\\\\Input_Files\\\\1.5M_Rows.csv')\n",
    "        \"\"\"\n",
    "\n",
    "# This prepares the query but doesn't execute it\n",
    "dbf_1point5m_rows = db.sql(query)\n",
    "lazytime_duckdb = time.perf_counter() - start_lazy\n",
    "\n",
    "# Actual Materialization of the Query\n",
    "start_action = time.perf_counter()\n",
    "\n",
    "# Triggering the DuckDB Query\n",
    "db_count_records = len(dbf_1point5m_rows.to_df())\n",
    "action_time_duckdb = time.perf_counter() - start_action\n",
    "\n",
    "print(\"Record Count: \", db_count_records)\n",
    "print(\"Timings for 1.5M Rows -->>>\")\n",
    "print(f\"DuckDb Lazy Read Time: {lazytime_duckdb: .2f} s\")\n",
    "print(f\"DuckDB Action Time: {action_time_duckdb: .2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cef88a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d7581c298c4461adba944ab666f6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record Count:  3906160\n",
      "Timings for 4M Rows -->>>\n",
      "DuckDb Lazy Read Time:  0.21 s\n",
      "DuckDB Action Time:  64.02 s\n"
     ]
    }
   ],
   "source": [
    "# DuckDB command to read a dataset for 4M records and convert to Pandas Dataframe\n",
    "# Lazy Read Simulation: Preparing the query\n",
    "start_lazy = time.perf_counter()\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT * FROM read_csv_auto(\n",
    "            'C:\\\\Users\\\\heyit\\\\Desktop\\\\Jupyter Notebooks\\\\PB Notebooks\\\\AKP_Tech_Playground\\\\DuckDB vs Pandas\\\\Input_Files\\\\4M_Rows.csv', parallel=false)\n",
    "        \"\"\"\n",
    "\n",
    "# This prepares the query but doesn't execute it\n",
    "dbf_4m_rows = db.sql(query)\n",
    "lazytime_duckdb = time.perf_counter() - start_lazy\n",
    "\n",
    "# Actual Materialization of the Query\n",
    "start_action = time.perf_counter()\n",
    "\n",
    "# Triggering the DuckDB Query\n",
    "db_count_records = len(dbf_4m_rows.to_df())\n",
    "action_time_duckdb = time.perf_counter() - start_action\n",
    "\n",
    "print(\"Record Count: \", db_count_records)\n",
    "print(\"Timings for 4M Rows -->>>\")\n",
    "print(f\"DuckDb Lazy Read Time: {lazytime_duckdb: .2f} s\")\n",
    "print(f\"DuckDB Action Time: {action_time_duckdb: .2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247be21a",
   "metadata": {},
   "source": [
    "##### B.  Checking the \"Sort\" Command on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60c53a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                                             name    host_id  \\\n",
      "0  10830083                Beautiful well kept private home!   56078939   \n",
      "1  35489384                                   Cozy Apartment  236186921   \n",
      "2  12230928                   Villa DiGioia visit NYC via SI   65806798   \n",
      "3    639199  Beautiful 4BR/4BA Home, Staten Island, NY City.    1483081   \n",
      "4  18997371                                     Cozy Getaway   90104417   \n",
      "\n",
      "   host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
      "0       Tony       Staten Island   Tottenville  40.49979  -74.24084   \n",
      "1      Iveth       Staten Island   Tottenville  40.50641  -74.23059   \n",
      "2  Michael J       Staten Island   Tottenville  40.50708  -74.24285   \n",
      "3     Marina       Staten Island   Tottenville  40.50868  -74.23986   \n",
      "4     Sueann       Staten Island   Tottenville  40.50873  -74.23914   \n",
      "\n",
      "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
      "0     Private room    110               2                  0         NaT   \n",
      "1  Entire home/apt     75               1                  1  2019-06-28   \n",
      "2     Private room    100               2                  0         NaT   \n",
      "3  Entire home/apt    299               3                 59  2019-07-08   \n",
      "4  Entire home/apt     85               2                 49  2019-07-01   \n",
      "\n",
      "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
      "0                NaN                               1               364  \n",
      "1               1.00                               1               299  \n",
      "2                NaN                               1               365  \n",
      "3               0.82                               1               245  \n",
      "4               2.08                               2               159  \n",
      "Timings for Sorting 50K Rows -->>>\n",
      "DuckDb Lazy Read Time:  0.26 s\n",
      "DuckDB Action Time:  0.38 s\n"
     ]
    }
   ],
   "source": [
    "# DuckDB command to sort a dataset of 50k records and convert to Pandas Dataframe\n",
    "# Lazy Read Simulation: Preparing the query\n",
    "start_lazy = time.perf_counter()\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT * FROM dbf_50k_rows\n",
    "        ORDER BY latitude ASC\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "\n",
    "# This prepares the query but doesn't execute it\n",
    "dbf_50k_sorted = db.sql(query)\n",
    "lazytime_duckdb = time.perf_counter() - start_lazy\n",
    "\n",
    "# Actual Materialization of the Query\n",
    "start_action = time.perf_counter()\n",
    "\n",
    "# Triggering the DuckDB Query\n",
    "pdf_50k_sorted = dbf_50k_sorted.to_df()\n",
    "print(pdf_50k_sorted.head())\n",
    "action_time_duckdb = time.perf_counter() - start_action\n",
    "\n",
    "print(\"Timings for Sorting 50K Rows -->>>\")\n",
    "print(f\"DuckDb Lazy Read Time: {lazytime_duckdb: .2f} s\")\n",
    "print(f\"DuckDB Action Time: {action_time_duckdb: .2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35e9fe4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   column00                track_id                                 artists  \\\n",
      "0     65900  1kR4gIb7nGxHPI3D2ifs59                                    None   \n",
      "1     59310  6hsyfegVY5yklJneM40mWi                              Leila Bela   \n",
      "2     59812  38Ogh3rsHba83kXx13gbKs                              Leila Bela   \n",
      "3     59775  1HVjSh7scH1PaPiLjy2LEu          Leila Bela;Leila's Opera Class   \n",
      "4     16856  5YKCM3jbJ8lqUXUwfU7KwZ  Wolfgang Amadeus Mozart;Ingrid Haebler   \n",
      "\n",
      "                           album_name  \\\n",
      "0                                None   \n",
      "1                         Angra Manyu   \n",
      "2                         Angra Manyu   \n",
      "3                         Angra Manyu   \n",
      "4  Mozart: The Complete Piano Sonatas   \n",
      "\n",
      "                                          track_name  popularity  duration_ms  \\\n",
      "0                                               None           0            0   \n",
      "1                             The Exorsism Begins...           0         8586   \n",
      "2                                                V-4           0        13386   \n",
      "3  Screams for a Finale! (feat. Leila's Opera Class)           0        15800   \n",
      "4                          Andante in C Major, K. 1a           0        17453   \n",
      "\n",
      "   explicit  danceability  energy  ...  loudness  mode  speechiness  \\\n",
      "0     False         0.501  0.5830  ...    -9.460     0       0.0605   \n",
      "1     False         0.000  0.0400  ...   -29.714     0       0.0000   \n",
      "2     False         0.000  0.2240  ...   -22.196     1       0.0000   \n",
      "3     False         0.251  0.5080  ...   -10.564     0       0.3160   \n",
      "4     False         0.467  0.0301  ...   -28.518     0       0.0428   \n",
      "\n",
      "   acousticness  instrumentalness  liveness  valence    tempo  time_signature  \\\n",
      "0         0.690           0.00396    0.0747    0.734  138.391               4   \n",
      "1         0.928           0.95600    0.1150    0.000    0.000               0   \n",
      "2         0.970           0.00000    0.9070    0.000    0.000               0   \n",
      "3         0.969           0.99900    0.9520    0.000  184.051               3   \n",
      "4         0.995           0.90000    0.1240    0.000   84.375               4   \n",
      "\n",
      "   track_genre  \n",
      "0        k-pop  \n",
      "1      iranian  \n",
      "2      iranian  \n",
      "3      iranian  \n",
      "4    classical  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Timings for Sorting 100K Rows -->>>\n",
      "DuckDb Lazy Read Time:  0.11 s\n",
      "DuckDB Action Time:  0.19 s\n"
     ]
    }
   ],
   "source": [
    "# DuckDB command to sort a dataset of 100k records and convert to Pandas Dataframe\n",
    "# Lazy Read Simulation: Preparing the query\n",
    "start_lazy = time.perf_counter()\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT * FROM dbf_100k_rows\n",
    "        ORDER BY duration_ms ASC\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "\n",
    "# This prepares the query but doesn't execute it\n",
    "dbf_100k_sorted = db.sql(query)\n",
    "lazytime_duckdb = time.perf_counter() - start_lazy\n",
    "\n",
    "# Actual Materialization of the Query\n",
    "start_action = time.perf_counter()\n",
    "\n",
    "# Triggering the DuckDB Query\n",
    "pdf_100k_sorted = dbf_100k_sorted.to_df()\n",
    "print(pdf_100k_sorted.head())\n",
    "action_time_duckdb = time.perf_counter() - start_action\n",
    "\n",
    "print(\"Timings for Sorting 100K Rows -->>>\")\n",
    "print(f\"DuckDb Lazy Read Time: {lazytime_duckdb: .2f} s\")\n",
    "print(f\"DuckDB Action Time: {action_time_duckdb: .2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da3f12a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Id   ProductId          UserId         ProfileName  \\\n",
      "0  150524     6641040   ACITT7DI6IDDL     shari zychinski   \n",
      "1  150501     6641040   AJ46FKXOVC7NR  Nicholas A Mesiano   \n",
      "2  451856  B00004CXX9   AIUWLEQ1ADEG5    Elizabeth Medina   \n",
      "3  374359  B00004CI84  A344SMIA5JECGM     Vincent P. Ross   \n",
      "4  451878  B00004CXX9  A344SMIA5JECGM     Vincent P. Ross   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score       Time  \\\n",
      "0                     0                       0      5  939340800   \n",
      "1                     2                       2      5  940809600   \n",
      "2                     0                       0      5  944092800   \n",
      "3                     1                       2      5  944438400   \n",
      "4                     1                       2      5  944438400   \n",
      "\n",
      "                                             Summary  \\\n",
      "0                          EVERY book is educational   \n",
      "1  This whole series is great way to spend time w...   \n",
      "2                               Entertainingl Funny!   \n",
      "3                            A modern day fairy tale   \n",
      "4                            A modern day fairy tale   \n",
      "\n",
      "                                                Text  \n",
      "0  this witty little book makes my son laugh at l...  \n",
      "1  I can remember seeing the show when it aired o...  \n",
      "2  Beetlejuice is a well written movie ..... ever...  \n",
      "3  A twist of rumplestiskin captured on film, sta...  \n",
      "4  A twist of rumplestiskin captured on film, sta...  \n",
      "Timings for Sorting 500K Rows -->>>\n",
      "DuckDb Lazy Read Time:  0.20 s\n",
      "DuckDB Action Time:  0.41 s\n"
     ]
    }
   ],
   "source": [
    "# DuckDB command to sort a dataset of 500k records and convert to Pandas Dataframe\n",
    "# Lazy Read Simulation: Preparing the query\n",
    "start_lazy = time.perf_counter()\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT * FROM dbf_500k_rows\n",
    "        ORDER BY Time ASC\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "\n",
    "# This prepares the query but doesn't execute it\n",
    "dbf_500k_sorted = db.sql(query)\n",
    "lazytime_duckdb = time.perf_counter() - start_lazy\n",
    "\n",
    "# Actual Materialization of the Query\n",
    "start_action = time.perf_counter()\n",
    "\n",
    "# Triggering the DuckDB Query\n",
    "pdf_500k_sorted = dbf_500k_sorted.to_df()\n",
    "print(pdf_500k_sorted.head())\n",
    "action_time_duckdb = time.perf_counter() - start_action\n",
    "\n",
    "print(\"Timings for Sorting 500K Rows -->>>\")\n",
    "print(f\"DuckDb Lazy Read Time: {lazytime_duckdb: .2f} s\")\n",
    "print(f\"DuckDB Action Time: {action_time_duckdb: .2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3d1eb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                id  reviewId creationDate        criticName  \\\n",
      "0       1202487-book_of_revelation   1892314   1800-01-01      Mike Barnard   \n",
      "1  1013485-masque_of_the_red_death   1908664   1800-01-01    Jennie Kermode   \n",
      "2        the-jolly-boys-last-stand   1906693   1800-01-01  Christopher Null   \n",
      "3                       we_believe   1901976   1800-01-01    Erik Childress   \n",
      "4                      accomplices   1914020   1800-01-01       Roger Ebert   \n",
      "\n",
      "   isTopCritic originalScore reviewState     publicatioName  \\\n",
      "0        False          5/10      rotten   Future Movies UK   \n",
      "1        False           5/5       fresh       Eye for Film   \n",
      "2        False           3/5       fresh     Filmcritic.com   \n",
      "3        False           4/5       fresh    eFilmCritic.com   \n",
      "4         True           3/4       fresh  Chicago Sun-Times   \n",
      "\n",
      "                                          reviewText scoreSentiment  \\\n",
      "0                                               None       NEGATIVE   \n",
      "1                                               None       POSITIVE   \n",
      "2                                               None       POSITIVE   \n",
      "3                                               None       POSITIVE   \n",
      "4  All four of these actors are completely natura...       POSITIVE   \n",
      "\n",
      "                                           reviewUrl  \n",
      "0    http://www.futuremovies.co.uk/review.asp?ID=900  \n",
      "1    http://www.eyeforfilm.co.uk/reviews.php?id=8025  \n",
      "2                                               None  \n",
      "3  http://efilmcritic.com/review.php?movie=19104&...  \n",
      "4  http://www.rogerebert.com/reviews/accomplices-...  \n",
      "Timings for Sorting 1.5M Rows -->>>\n",
      "DuckDb Lazy Read Time:  0.15 s\n",
      "DuckDB Action Time:  0.43 s\n"
     ]
    }
   ],
   "source": [
    "# DuckDB command to sort a dataset of 1.5M records and convert to Pandas Dataframe\n",
    "# Lazy Read Simulation: Preparing the query\n",
    "start_lazy = time.perf_counter()\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT * FROM dbf_1point5m_rows\n",
    "        ORDER BY creationDate ASC\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "\n",
    "# This prepares the query but doesn't execute it\n",
    "dbf_1point5m_sorted = db.sql(query)\n",
    "lazytime_duckdb = time.perf_counter() - start_lazy\n",
    "\n",
    "# Actual Materialization of the Query\n",
    "start_action = time.perf_counter()\n",
    "\n",
    "# Triggering the DuckDB Query\n",
    "pdf_1point5m_sorted = dbf_1point5m_sorted.to_df()\n",
    "print(pdf_1point5m_sorted.head())\n",
    "action_time_duckdb = time.perf_counter() - start_action\n",
    "\n",
    "print(\"Timings for Sorting 1.5M Rows -->>>\")\n",
    "print(f\"DuckDb Lazy Read Time: {lazytime_duckdb: .2f} s\")\n",
    "print(f\"DuckDB Action Time: {action_time_duckdb: .2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cb47d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec30ae8da3041a895a94ac749e76ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                        name              universal_name  \\\n",
      "0   941149            Sresht Solutions            sresht-solutions   \n",
      "1  4298371           Acorn Woodworking           acorn-woodworking   \n",
      "2   941335  Cross Rhoades Technologies  cross-rhoades-technologies   \n",
      "3  4298386                  Crc Claims                  crc-claims   \n",
      "4  2652944            PedalMonsters.co            pedalmonsters-co   \n",
      "\n",
      "                                         description  \\\n",
      "0  Sresht Solutions is a training and development...   \n",
      "1                                               None   \n",
      "2  Check out www.cross-rhoades.com to see what we...   \n",
      "3                                               None   \n",
      "4                                               None   \n",
      "\n",
      "                                        linkedin_url  \\\n",
      "0  https://www.linkedin.com/company/sresht-soluti...   \n",
      "1  https://www.linkedin.com/company/acorn-woodwor...   \n",
      "2  https://www.linkedin.com/company/cross-rhoades...   \n",
      "3       https://www.linkedin.com/company/crc-claims/   \n",
      "4  https://www.linkedin.com/company/pedalmonsters...   \n",
      "\n",
      "                    website_url  followers_count  associated_members_count  \\\n",
      "0                          None                0                         0   \n",
      "1       http://www.acornwd.com/                0                         4   \n",
      "2  http://www.cross-rhoades.com                0                         0   \n",
      "3                          None                0                         3   \n",
      "4                          None                0                         0   \n",
      "\n",
      "          verification founded_on  ...  \\\n",
      "0  {\"verified\": false}       None  ...   \n",
      "1  {\"verified\": false}       None  ...   \n",
      "2  {\"verified\": false}       None  ...   \n",
      "3  {\"verified\": false}       None  ...   \n",
      "4  {\"verified\": false}       None  ...   \n",
      "\n",
      "                                   location_branches  \\\n",
      "0  [{\"name\": \"India\", \"address\": {\"country\": \"IN\"...   \n",
      "1  [{\"name\": \"Filer\", \"address\": {\"city\": \"Filer\"...   \n",
      "2  [{\"name\": \"Greater Idaho Falls\", \"address\": {\"...   \n",
      "3  [{\"name\": \"Braintree\", \"address\": {\"city\": \"Br...   \n",
      "4                                                 []   \n",
      "\n",
      "                                            logo_url specialities  \\\n",
      "0  https://media.licdn.com/dms/image/v2/C4E0BAQEg...         None   \n",
      "1                                               None         None   \n",
      "2                                               None         None   \n",
      "3                                               None         None   \n",
      "4                                               None         None   \n",
      "\n",
      "                            industry hashtags funding_info  \\\n",
      "0               Education Management     None         None   \n",
      "1             Religious Institutions     None         None   \n",
      "2  Information Technology & Services     None         None   \n",
      "3                Travel Arrangements     None         None   \n",
      "4                               None     None         None   \n",
      "\n",
      "                      __created_at                     __updated_at claimable  \\\n",
      "0 2025-06-21 13:23:28.488144+05:30 2025-06-21 13:23:28.488144+05:30      True   \n",
      "1 2025-06-22 21:50:05.781512+05:30 2025-06-22 21:50:05.781512+05:30      True   \n",
      "2 2025-06-21 13:24:07.886737+05:30 2025-06-21 13:24:07.886737+05:30      True   \n",
      "3 2025-06-22 21:50:08.127662+05:30 2025-06-22 21:50:08.127662+05:30      True   \n",
      "4 2025-06-21 13:24:06.161751+05:30 2025-06-21 13:24:06.161751+05:30      True   \n",
      "\n",
      "   company_type  \n",
      "0       company  \n",
      "1       company  \n",
      "2       company  \n",
      "3       company  \n",
      "4       company  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Timings for Sorting 4M Rows -->>>\n",
      "DuckDb Lazy Read Time:  0.21 s\n",
      "DuckDB Action Time:  38.80 s\n"
     ]
    }
   ],
   "source": [
    "# DuckDB command to sort a dataset of 4M records and convert to Pandas Dataframe\n",
    "# Lazy Read Simulation: Preparing the query\n",
    "start_lazy = time.perf_counter()\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT * FROM dbf_4m_rows\n",
    "        ORDER BY followers_count ASC\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "\n",
    "# This prepares the query but doesn't execute it\n",
    "dbf_4m_sorted = db.sql(query)\n",
    "lazytime_duckdb = time.perf_counter() - start_lazy\n",
    "\n",
    "# Actual Materialization of the Query\n",
    "start_action = time.perf_counter()\n",
    "\n",
    "# Triggering the DuckDB Query\n",
    "pdf_4m_sorted = dbf_4m_sorted.to_df()\n",
    "print(pdf_4m_sorted.head())\n",
    "action_time_duckdb = time.perf_counter() - start_action\n",
    "\n",
    "print(\"Timings for Sorting 4M Rows -->>>\")\n",
    "print(f\"DuckDb Lazy Read Time: {lazytime_duckdb: .2f} s\")\n",
    "print(f\"DuckDB Action Time: {action_time_duckdb: .2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d19c9e",
   "metadata": {},
   "source": [
    "##### C.  Checking the \"Aggregation\" Command on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a39583c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         room_type   avg_price\n",
      "0     Private room   89.780973\n",
      "1  Entire home/apt  211.794246\n",
      "2      Shared room   70.127586\n",
      "Timings for Aggregating 50K Rows -->>>\n",
      "DuckDb Lazy Read Time:  0.12 s\n",
      "DuckDB Action Time:  0.19 s\n"
     ]
    }
   ],
   "source": [
    "# DuckDB command to aggregate a dataset of 50k records and convert to Pandas Dataframe\n",
    "# Lazy Read Simulation: Preparing the query\n",
    "start_lazy = time.perf_counter()\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT room_type, AVG(price) AS avg_price \n",
    "        FROM dbf_50k_rows\n",
    "        GROUP BY room_type\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "\n",
    "# This prepares the query but doesn't execute it\n",
    "dbf_50k_aggregated = db.sql(query)\n",
    "lazytime_duckdb = time.perf_counter() - start_lazy\n",
    "\n",
    "# Actual Materialization of the Query\n",
    "start_action = time.perf_counter()\n",
    "\n",
    "# Triggering the DuckDB Query\n",
    "pdf_50k_aggregated = dbf_50k_aggregated.to_df()\n",
    "print(pdf_50k_aggregated.head())\n",
    "action_time_duckdb = time.perf_counter() - start_action\n",
    "\n",
    "print(\"Timings for Aggregating 50K Rows -->>>\")\n",
    "print(f\"DuckDb Lazy Read Time: {lazytime_duckdb: .2f} s\")\n",
    "print(f\"DuckDB Action Time: {action_time_duckdb: .2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e4144e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  track_genre  avg_duration_ms\n",
      "0       sleep       184058.980\n",
      "1   synth-pop       244805.907\n",
      "2     turkish       219529.010\n",
      "3      j-idol       256122.622\n",
      "4       piano       203966.541\n",
      "Timings for Aggregating 100K Rows -->>>\n",
      "DuckDb Lazy Read Time:  0.12 s\n",
      "DuckDB Action Time:  0.12 s\n"
     ]
    }
   ],
   "source": [
    "# DuckDB command to aggregate a dataset of 100k records and convert to Pandas Dataframe\n",
    "# Lazy Read Simulation: Preparing the query\n",
    "start_lazy = time.perf_counter()\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT track_genre, AVG(duration_ms) AS avg_duration_ms\n",
    "        FROM dbf_100k_rows\n",
    "        GROUP BY track_genre\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "\n",
    "# This prepares the query but doesn't execute it\n",
    "dbf_100k_aggregated = db.sql(query)\n",
    "lazytime_duckdb = time.perf_counter() - start_lazy\n",
    "\n",
    "# Actual Materialization of the Query\n",
    "start_action = time.perf_counter()\n",
    "\n",
    "# Triggering the DuckDB Query\n",
    "pdf_100k_aggregated = dbf_100k_aggregated.to_df()\n",
    "print(pdf_100k_aggregated.head())\n",
    "action_time_duckdb = time.perf_counter() - start_action\n",
    "\n",
    "print(\"Timings for Aggregating 100K Rows -->>>\")\n",
    "print(f\"DuckDb Lazy Read Time: {lazytime_duckdb: .2f} s\")\n",
    "print(f\"DuckDB Action Time: {action_time_duckdb: .2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb574f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score      avg_Time\n",
      "0      4  1.296722e+09\n",
      "1      3  1.300126e+09\n",
      "2      5  1.294306e+09\n",
      "3      2  1.301131e+09\n",
      "4      1  1.303159e+09\n",
      "Timings for Aggregating 500K Rows -->>>\n",
      "DuckDb Lazy Read Time:  0.12 s\n",
      "DuckDB Action Time:  0.38 s\n"
     ]
    }
   ],
   "source": [
    "# DuckDB command to aggregate a dataset of 500k records and convert to Pandas Dataframe\n",
    "# Lazy Read Simulation: Preparing the query\n",
    "start_lazy = time.perf_counter()\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT Score, AVG(Time) AS avg_Time\n",
    "        FROM dbf_500k_rows\n",
    "        GROUP BY Score\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "\n",
    "# This prepares the query but doesn't execute it\n",
    "dbf_500k_aggregated = db.sql(query)\n",
    "lazytime_duckdb = time.perf_counter() - start_lazy\n",
    "\n",
    "# Actual Materialization of the Query\n",
    "start_action = time.perf_counter()\n",
    "\n",
    "# Triggering the DuckDB Query\n",
    "pdf_500k_aggregated = dbf_500k_aggregated.to_df()\n",
    "print(pdf_500k_aggregated.head())\n",
    "action_time_duckdb = time.perf_counter() - start_action\n",
    "\n",
    "print(\"Timings for Aggregating 500K Rows -->>>\")\n",
    "print(f\"DuckDb Lazy Read Time: {lazytime_duckdb: .2f} s\")\n",
    "print(f\"DuckDB Action Time: {action_time_duckdb: .2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4259e036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  reviewState max_creationDate\n",
      "0       fresh       2023-04-08\n",
      "1      rotten       2023-04-08\n",
      "Timings for Aggregating 1.5M Rows -->>>\n",
      "DuckDb Lazy Read Time:  0.13 s\n",
      "DuckDB Action Time:  0.41 s\n"
     ]
    }
   ],
   "source": [
    "# DuckDB command to aggregate a dataset of 1.5M records and convert to Pandas Dataframe\n",
    "# Lazy Read Simulation: Preparing the query\n",
    "start_lazy = time.perf_counter()\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT reviewState, MAX(creationDate) AS max_creationDate\n",
    "        FROM dbf_1point5m_rows\n",
    "        GROUP BY reviewState\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "\n",
    "# This prepares the query but doesn't execute it\n",
    "dbf_1point5m_aggregated = db.sql(query)\n",
    "lazytime_duckdb = time.perf_counter() - start_lazy\n",
    "\n",
    "# Actual Materialization of the Query\n",
    "start_action = time.perf_counter()\n",
    "\n",
    "# Triggering the DuckDB Query\n",
    "pdf_1point5m_aggregated = dbf_1point5m_aggregated.to_df()\n",
    "print(pdf_1point5m_aggregated.head())\n",
    "action_time_duckdb = time.perf_counter() - start_action\n",
    "\n",
    "print(\"Timings for Aggregating 1.5M Rows -->>>\")\n",
    "print(f\"DuckDb Lazy Read Time: {lazytime_duckdb: .2f} s\")\n",
    "print(f\"DuckDB Action Time: {action_time_duckdb: .2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "260a8231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac163f6fc0f247bcb8a5c13bade5ba2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               industry  avg_associated_members_count\n",
      "0  Alternative Medicine                     15.380152\n",
      "1    Financial Services                    109.446535\n",
      "2        Nanotechnology                     26.261307\n",
      "3   Program Development                      8.139057\n",
      "4          Philanthropy                     12.868830\n",
      "Timings for Aggregating 4M Rows -->>>\n",
      "DuckDb Lazy Read Time:  0.24 s\n",
      "DuckDB Action Time:  12.65 s\n"
     ]
    }
   ],
   "source": [
    "# DuckDB command to aggregate a dataset of 4M records and convert to Pandas Dataframe\n",
    "# Lazy Read Simulation: Preparing the query\n",
    "start_lazy = time.perf_counter()\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT industry, AVG(associated_members_count) AS avg_associated_members_count\n",
    "        FROM dbf_4m_rows\n",
    "        GROUP BY industry\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "\n",
    "# This prepares the query but doesn't execute it\n",
    "dbf_4m_aggregated = db.sql(query)\n",
    "lazytime_duckdb = time.perf_counter() - start_lazy\n",
    "\n",
    "# Actual Materialization of the Query\n",
    "start_action = time.perf_counter()\n",
    "\n",
    "# Triggering the DuckDB Query\n",
    "pdf_4m_aggregated = dbf_4m_aggregated.to_df()\n",
    "print(pdf_4m_aggregated.head())\n",
    "action_time_duckdb = time.perf_counter() - start_action\n",
    "\n",
    "print(\"Timings for Aggregating 4M Rows -->>>\")\n",
    "print(f\"DuckDb Lazy Read Time: {lazytime_duckdb: .2f} s\")\n",
    "print(f\"DuckDB Action Time: {action_time_duckdb: .2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3799d6",
   "metadata": {},
   "source": [
    "##### D.  Checking the \"Row-Wise Transformation\" Command on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4f8f015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id                                              name  host_id  \\\n",
      "0  2539                Clean & quiet apt home by the park     2787   \n",
      "1  2595                             Skylit Midtown Castle     2845   \n",
      "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n",
      "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
      "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
      "\n",
      "     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
      "0         John            Brooklyn    Kensington  40.64749  -73.97237   \n",
      "1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n",
      "2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n",
      "3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n",
      "4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n",
      "\n",
      "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
      "0     Private room    149               1                  9  2018-10-19   \n",
      "1  Entire home/apt    225               1                 45  2019-05-21   \n",
      "2     Private room    150               3                  0         NaT   \n",
      "3  Entire home/apt     89               1                270  2019-07-05   \n",
      "4  Entire home/apt     80              10                  9  2018-11-19   \n",
      "\n",
      "   reviews_per_month  calculated_host_listings_count  availability_365  \\\n",
      "0               0.21                               6               365   \n",
      "1               0.38                               2               355   \n",
      "2                NaN                               1               365   \n",
      "3               4.64                               1               194   \n",
      "4               0.10                               1                 0   \n",
      "\n",
      "   price_converted  \n",
      "0           175.82  \n",
      "1           265.50  \n",
      "2           177.00  \n",
      "3           105.02  \n",
      "4            94.40  \n",
      "Timings for Transforming 50K Rows -->>>\n",
      "DuckDb Lazy Read Time:  0.09 s\n",
      "DuckDB Action Time:  0.14 s\n"
     ]
    }
   ],
   "source": [
    "# DuckDB command to aggregate a dataset of 50k records and convert to Pandas Dataframe\n",
    "# Lazy Read Simulation: Preparing the query\n",
    "start_lazy = time.perf_counter()\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT *, price * 1.18 AS price_converted \n",
    "        FROM dbf_50k_rows\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "\n",
    "# This prepares the query but doesn't execute it\n",
    "dbf_50k_transformed = db.sql(query)\n",
    "lazytime_duckdb = time.perf_counter() - start_lazy\n",
    "\n",
    "# Actual Materialization of the Query\n",
    "start_action = time.perf_counter()\n",
    "\n",
    "# Triggering the DuckDB Query\n",
    "pdf_50k_transformed = dbf_50k_transformed.to_df()\n",
    "print(pdf_50k_transformed.head())\n",
    "action_time_duckdb = time.perf_counter() - start_action\n",
    "\n",
    "print(\"Timings for Transforming 50K Rows -->>>\")\n",
    "print(f\"DuckDb Lazy Read Time: {lazytime_duckdb: .2f} s\")\n",
    "print(f\"DuckDB Action Time: {action_time_duckdb: .2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd3a15da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   column00                track_id                 artists  \\\n",
      "0         0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n",
      "1         1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n",
      "2         2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n",
      "3         3  6lfxq3CG4xtTiEg7opyCyx            Kina Grannis   \n",
      "4         4  5vjLSffimiIP26QG5WcN2K        Chord Overstreet   \n",
      "\n",
      "                                          album_name  \\\n",
      "0                                             Comedy   \n",
      "1                                   Ghost (Acoustic)   \n",
      "2                                     To Begin Again   \n",
      "3  Crazy Rich Asians (Original Motion Picture Sou...   \n",
      "4                                            Hold On   \n",
      "\n",
      "                   track_name  popularity  duration_ms  explicit  \\\n",
      "0                      Comedy          73       230666     False   \n",
      "1            Ghost - Acoustic          55       149610     False   \n",
      "2              To Begin Again          57       210826     False   \n",
      "3  Can't Help Falling In Love          71       201933     False   \n",
      "4                     Hold On          82       198853     False   \n",
      "\n",
      "   danceability  energy  ...  mode  speechiness  acousticness  \\\n",
      "0         0.676  0.4610  ...     0       0.1430        0.0322   \n",
      "1         0.420  0.1660  ...     1       0.0763        0.9240   \n",
      "2         0.438  0.3590  ...     1       0.0557        0.2100   \n",
      "3         0.266  0.0596  ...     1       0.0363        0.9050   \n",
      "4         0.618  0.4430  ...     1       0.0526        0.4690   \n",
      "\n",
      "   instrumentalness  liveness  valence    tempo  time_signature  track_genre  \\\n",
      "0          0.000001    0.3580    0.715   87.917               4     acoustic   \n",
      "1          0.000006    0.1010    0.267   77.489               4     acoustic   \n",
      "2          0.000000    0.1170    0.120   76.332               4     acoustic   \n",
      "3          0.000071    0.1320    0.143  181.740               3     acoustic   \n",
      "4          0.000000    0.0829    0.167  119.949               4     acoustic   \n",
      "\n",
      "   duration_ms_converted  \n",
      "0              272185.88  \n",
      "1              176539.80  \n",
      "2              248774.68  \n",
      "3              238280.94  \n",
      "4              234646.54  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "Timings for Transforming 100K Rows -->>>\n",
      "DuckDb Lazy Read Time:  0.09 s\n",
      "DuckDB Action Time:  0.11 s\n"
     ]
    }
   ],
   "source": [
    "# DuckDB command to aggregate a dataset of 100k records and convert to Pandas Dataframe\n",
    "# Lazy Read Simulation: Preparing the query\n",
    "start_lazy = time.perf_counter()\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT *, duration_ms * 1.18 AS duration_ms_converted \n",
    "        FROM dbf_100k_rows\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "\n",
    "# This prepares the query but doesn't execute it\n",
    "dbf_100k_transformed = db.sql(query)\n",
    "lazytime_duckdb = time.perf_counter() - start_lazy\n",
    "\n",
    "# Actual Materialization of the Query\n",
    "start_action = time.perf_counter()\n",
    "\n",
    "# Triggering the DuckDB Query\n",
    "pdf_100k_transformed = dbf_100k_transformed.to_df()\n",
    "print(pdf_100k_transformed.head())\n",
    "action_time_duckdb = time.perf_counter() - start_action\n",
    "\n",
    "print(\"Timings for Transforming 100K Rows -->>>\")\n",
    "print(f\"DuckDb Lazy Read Time: {lazytime_duckdb: .2f} s\")\n",
    "print(f\"DuckDB Action Time: {action_time_duckdb: .2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1012899c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id   ProductId          UserId                      ProfileName  \\\n",
      "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
      "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
      "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
      "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
      "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
      "\n",
      "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
      "0                     1                       1      5  1303862400   \n",
      "1                     0                       0      1  1346976000   \n",
      "2                     1                       1      4  1219017600   \n",
      "3                     3                       3      2  1307923200   \n",
      "4                     0                       0      5  1350777600   \n",
      "\n",
      "                 Summary                                               Text  \\\n",
      "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
      "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
      "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
      "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
      "4            Great taffy  Great taffy at a great price.  There was a wid...   \n",
      "\n",
      "   Time_converted  \n",
      "0    1.538558e+09  \n",
      "1    1.589432e+09  \n",
      "2    1.438441e+09  \n",
      "3    1.543349e+09  \n",
      "4    1.593918e+09  \n",
      "Timings for Transforming 500K Rows -->>>\n",
      "DuckDb Lazy Read Time:  0.13 s\n",
      "DuckDB Action Time:  0.15 s\n"
     ]
    }
   ],
   "source": [
    "# DuckDB command to aggregate a dataset of 500k records and convert to Pandas Dataframe\n",
    "# Lazy Read Simulation: Preparing the query\n",
    "start_lazy = time.perf_counter()\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT *, Time * 1.18 AS Time_converted \n",
    "        FROM dbf_500k_rows\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "\n",
    "# This prepares the query but doesn't execute it\n",
    "dbf_500k_transformed = db.sql(query)\n",
    "lazytime_duckdb = time.perf_counter() - start_lazy\n",
    "\n",
    "# Actual Materialization of the Query\n",
    "start_action = time.perf_counter()\n",
    "\n",
    "# Triggering the DuckDB Query\n",
    "pdf_500k_transformed = dbf_500k_transformed.to_df()\n",
    "print(pdf_500k_transformed.head())\n",
    "action_time_duckdb = time.perf_counter() - start_action\n",
    "\n",
    "print(\"Timings for Transforming 500K Rows -->>>\")\n",
    "print(f\"DuckDb Lazy Read Time: {lazytime_duckdb: .2f} s\")\n",
    "print(f\"DuckDB Action Time: {action_time_duckdb: .2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b39f6579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  id  reviewId creationDate       criticName  \\\n",
      "0                            beavers   1145982   2003-05-23  Ivan M. Lincoln   \n",
      "1                         blood_mask   1636744   2007-06-02    The Foywonder   \n",
      "2  city_hunter_shinjuku_private_eyes   2590987   2019-05-28     Reuben Baron   \n",
      "3  city_hunter_shinjuku_private_eyes   2558908   2019-02-14      Matt Schley   \n",
      "4                 dangerous_men_2015   2504681   2018-08-29        Pat Padua   \n",
      "\n",
      "   isTopCritic originalScore reviewState                 publicatioName  \\\n",
      "0        False         3.5/4       fresh  Deseret News (Salt Lake City)   \n",
      "1        False           1/5      rotten                  Dread Central   \n",
      "2        False          None       fresh                            CBR   \n",
      "3        False         2.5/5      rotten                    Japan Times   \n",
      "4        False          None       fresh                          DCist   \n",
      "\n",
      "                                          reviewText scoreSentiment  \\\n",
      "0  Timed to be just long enough for most youngste...       POSITIVE   \n",
      "1  It doesn't matter if a movie costs 300 million...       NEGATIVE   \n",
      "2  The choreography is so precise and lifelike at...       POSITIVE   \n",
      "3  The film's out-of-touch attempts at humor may ...       NEGATIVE   \n",
      "4  Its clumsy determination is endearing and some...       POSITIVE   \n",
      "\n",
      "                                           reviewUrl  reviewId_converted  \n",
      "0  http://www.deseretnews.com/article/700003233/B...          1352258.76  \n",
      "1  http://www.dreadcentral.com/index.php?name=Rev...          1931357.92  \n",
      "2  https://www.cbr.com/city-hunter-shinjuku-priva...          3057364.66  \n",
      "3  https://www.japantimes.co.jp/culture/2019/02/0...          3019511.44  \n",
      "4  http://dcist.com/2015/11/out_of_frame_dangerou...          2955523.58  \n",
      "Timings for Transforming 1.5M Rows -->>>\n",
      "DuckDb Lazy Read Time:  0.10 s\n",
      "DuckDB Action Time:  0.13 s\n"
     ]
    }
   ],
   "source": [
    "# DuckDB command to aggregate a dataset of 1.5M records and convert to Pandas Dataframe\n",
    "# Lazy Read Simulation: Preparing the query\n",
    "start_lazy = time.perf_counter()\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT *, reviewId * 1.18 AS reviewId_converted \n",
    "        FROM dbf_1point5m_rows\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "\n",
    "# This prepares the query but doesn't execute it\n",
    "dbf_1point5m_transformed = db.sql(query)\n",
    "lazytime_duckdb = time.perf_counter() - start_lazy\n",
    "\n",
    "# Actual Materialization of the Query\n",
    "start_action = time.perf_counter()\n",
    "\n",
    "# Triggering the DuckDB Query\n",
    "pdf_1point5m_transformed = dbf_1point5m_transformed.to_df()\n",
    "print(pdf_1point5m_transformed.head())\n",
    "action_time_duckdb = time.perf_counter() - start_action\n",
    "\n",
    "print(\"Timings for Transforming 1.5M Rows -->>>\")\n",
    "print(f\"DuckDb Lazy Read Time: {lazytime_duckdb: .2f} s\")\n",
    "print(f\"DuckDB Action Time: {action_time_duckdb: .2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc345312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                               name  \\\n",
      "0   940965                 Bow Plumbing Group   \n",
      "1   940966  BIONUTRIS CONSULTORIA EM NUTRIÇÃO   \n",
      "2   940967                    Essèntium Group   \n",
      "3  2652650               studio legale funari   \n",
      "4  2652651                  DEMA Partners LTD   \n",
      "\n",
      "                     universal_name  \\\n",
      "0                bow-plumbing-group   \n",
      "1  bionutris-consultoria-em-nutri-o   \n",
      "2        ess-ntium-consulting-group   \n",
      "3              studio-legale-funari   \n",
      "4                 dema-partners-ltd   \n",
      "\n",
      "                                         description  \\\n",
      "0  Founded in 1939, Bow Plumbing Group is one of ...   \n",
      "1  É com muita satisfação que lhe apresentamos BI...   \n",
      "2  Essèntium Group is a full-service consulting f...   \n",
      "3                                               None   \n",
      "4  Dema Partners LTD is a professional group of c...   \n",
      "\n",
      "                                        linkedin_url  \\\n",
      "0  https://www.linkedin.com/company/bow-plumbing-...   \n",
      "1  https://www.linkedin.com/company/bionutris-con...   \n",
      "2  https://www.linkedin.com/company/ess-ntium-con...   \n",
      "3  https://www.linkedin.com/company/studio-legale...   \n",
      "4  https://www.linkedin.com/company/dema-partners...   \n",
      "\n",
      "                        website_url  followers_count  \\\n",
      "0          http://www.bow-group.com              964   \n",
      "1       http://www.bionutris.com.br             3275   \n",
      "2          http://www.essentium.net              100   \n",
      "3                              None                6   \n",
      "4  http://www.worldwideoffshore.com              437   \n",
      "\n",
      "   associated_members_count         verification  \\\n",
      "0                        66  {\"verified\": false}   \n",
      "1                         3  {\"verified\": false}   \n",
      "2                         0  {\"verified\": false}   \n",
      "3                         1  {\"verified\": false}   \n",
      "4                         2  {\"verified\": false}   \n",
      "\n",
      "                                   founded_on  ...  \\\n",
      "0  {\"day\": null, \"year\": 1939, \"month\": null}  ...   \n",
      "1  {\"day\": null, \"year\": 2009, \"month\": null}  ...   \n",
      "2  {\"day\": null, \"year\": 2009, \"month\": null}  ...   \n",
      "3                                        None  ...   \n",
      "4  {\"day\": null, \"year\": 2000, \"month\": null}  ...   \n",
      "\n",
      "                                            logo_url  \\\n",
      "0  https://media.licdn.com/dms/image/v2/C4E0BAQHO...   \n",
      "1  https://media.licdn.com/dms/image/v2/C4E0BAQEQ...   \n",
      "2  https://media.licdn.com/dms/image/v2/C4E0BAQHU...   \n",
      "3                                               None   \n",
      "4  https://media.licdn.com/dms/image/v2/C4E0BAQGA...   \n",
      "\n",
      "                                        specialities               industry  \\\n",
      "0   {\"Plastic pipe\",\"Plastic fittings\",PEX,ABS,CPVC}               Plastics   \n",
      "1  {\"Consultoria nutricional em Restaurantes e Un...            Restaurants   \n",
      "2  {\"Project Management\",\"Government Relations\",B...   Government Relations   \n",
      "3                                               None                   None   \n",
      "4  {\"Offshore company formation and maintenance\",...  International Affairs   \n",
      "\n",
      "  hashtags                                       funding_info  \\\n",
      "0     None  {\"updated_at\": \"2025-04-24T05:35:59.000Z\", \"or...   \n",
      "1     None                                               None   \n",
      "2     None                                               None   \n",
      "3     None                                               None   \n",
      "4     None                                               None   \n",
      "\n",
      "                      __created_at                     __updated_at claimable  \\\n",
      "0 2025-06-21 13:22:45.851191+05:30 2025-06-21 13:22:45.851191+05:30     False   \n",
      "1 2025-06-21 13:22:45.851191+05:30 2025-06-21 13:22:45.851191+05:30     False   \n",
      "2 2025-06-21 13:22:45.851191+05:30 2025-06-21 13:22:45.851191+05:30      True   \n",
      "3 2025-06-21 13:22:48.745074+05:30 2025-06-21 13:22:48.745074+05:30     False   \n",
      "4 2025-06-21 13:22:48.745074+05:30 2025-06-21 13:22:48.745074+05:30     False   \n",
      "\n",
      "  company_type  associated_members_count_converted  \n",
      "0      company                               77.88  \n",
      "1      company                                3.54  \n",
      "2      company                                0.00  \n",
      "3      company                                1.18  \n",
      "4      company                                2.36  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "Timings for Transforming 4M Rows -->>>\n",
      "DuckDb Lazy Read Time:  0.18 s\n",
      "DuckDB Action Time:  0.24 s\n"
     ]
    }
   ],
   "source": [
    "# DuckDB command to aggregate a dataset of 4M records and convert to Pandas Dataframe\n",
    "# Lazy Read Simulation: Preparing the query\n",
    "start_lazy = time.perf_counter()\n",
    "\n",
    "query = \"\"\"\n",
    "        SELECT *, associated_members_count * 1.18 AS associated_members_count_converted \n",
    "        FROM dbf_4m_rows\n",
    "        LIMIT 5\n",
    "        \"\"\"\n",
    "\n",
    "# This prepares the query but doesn't execute it\n",
    "dbf_4m_transformed = db.sql(query)\n",
    "lazytime_duckdb = time.perf_counter() - start_lazy\n",
    "\n",
    "# Actual Materialization of the Query\n",
    "start_action = time.perf_counter()\n",
    "\n",
    "# Triggering the DuckDB Query\n",
    "pdf_4m_transformed = dbf_4m_transformed.to_df()\n",
    "print(pdf_4m_transformed.head())\n",
    "action_time_duckdb = time.perf_counter() - start_action\n",
    "\n",
    "print(\"Timings for Transforming 4M Rows -->>>\")\n",
    "print(f\"DuckDb Lazy Read Time: {lazytime_duckdb: .2f} s\")\n",
    "print(f\"DuckDB Action Time: {action_time_duckdb: .2f} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7f0947",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "<div style=\"text-align: center; width: fit-content; margin-left: 0;\">\n",
    "\n",
    "| Operation               | Dataset Size | Pandas Wall Time (s) | DuckDB Action Time (s) | Delta (s) [Pandas - DuckDB]|\n",
    "|:------------------------|:------------:|:--------------------:|:----------------------:|:------------------:|\n",
    "| Loading                 | 50k rows     | 0.28                 | 0.21                   | 0.07               |\n",
    "|                         | 100k rows    | 0.77                 | 0.28                   | 0.49               |\n",
    "|                         | 500k rows    | 6.16                 | 1.22                   | 4.94               |\n",
    "|                         | 1.5M rows    | 8.75                 | 3.03                   | 5.72               |\n",
    "|                         | 4M rows      | 97.00                | 64.02                  | 32.98              |\n",
    "| Sorting                 | 50k rows     | 0.04                 | 0.38                   | -0.34              |\n",
    "|                         | 100k rows    | 0.05                 | 0.19                   | -0.14              |\n",
    "|                         | 500k rows    | 0.25                 | 0.41                   | -0.16              |\n",
    "|                         | 1.5M rows    | 2.17                 | 0.43                   | 1.74               |\n",
    "|                         | 4M rows      | 8.23                 | 38.80                  | -30.57             |\n",
    "| Aggregating             | 50k rows     | 0.01                 | 0.19                   | -0.18              |\n",
    "|                         | 100k rows    | 0.01                 | 0.12                   | -0.11              |\n",
    "|                         | 500k rows    | 0.03                 | 0.38                   | -0.35              |\n",
    "|                         | 1.5M rows    | 0.20                 | 0.41                   | -0.21              |\n",
    "|                         | 4M rows      | 0.43                 | 12.65                  | -12.22             |\n",
    "| Row-Wise Transformation | 50k rows     | 0.02                 | 0.14                   | -0.12              |\n",
    "|                         | 100k rows    | 0.04                 | 0.11                   | -0.07              |\n",
    "|                         | 500k rows    | 0.14                 | 0.15                   | -0.01              |\n",
    "|                         | 1.5M rows    | 0.33                 | 0.13                   | 0.20               |\n",
    "|                         | 4M rows      | 0.76                 | 0.24                   | 0.52               |\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284f23a1",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "> - Pandas generally offers better performance for smaller datasets (up to around 500k rows) in most operations\n",
    "> - DuckDB significantly outperforms Pandas when dealing with large datasets (1.5M+ rows), particularly in loading and aggregation tasks, due to its ability to handle larger volumes efficiently\n",
    "> - For complex analytical queries and large-scale data processing, DuckDB's architectural advantages make it the more efficient choice from a pure runtime perspective"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
